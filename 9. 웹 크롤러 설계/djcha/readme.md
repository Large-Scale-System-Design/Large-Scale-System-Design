### 1\. 서론: 웹 크롤러란 무엇인가?

-   **정의:** 웹페이지를 탐색하며 데이터를 수집하고 인덱싱하는 자동화된 봇(Bot).

> 웹 크롤러는 로봇(robot) 또는 스파이더(spider)라고 부른다.  
> 검색 엔진에서 널리 쓰는 기술로, 웹에 새로 올라오거나 갱신된 콘텐츠를 찾아내는 것이 주 목적

### 1\. 웹 크롤러 이용 사례

-   검색 엔징 인덱싱: 구글 검색
-   웹 아카이빙: 나중에 사용할 목적으로 장기보관하기 위해 정보를 모으는 절차
-   웹 마이닝
-   웹 모니터링
-   가격 비교 사이트, 뉴스 애그리게이터, 데이터 분석, AI 학습

### 2\. 웹 크롤러 핵심 구성

-   미수집 URL 저장소: 다운로드 할 URL을 저장 관리하는 컴포넌트(URL Frontier)
-   HTML 다운로더: 웹페이지를 다운로드하는 컴포넌트
-   콘텐츠 파서: 웹 페이지 다운로드 후, 파싱과 검증 절차
-   콘텐츠 저장소
-   URL 추출기: HTML 페이지를 파싱하여 링크들만 골라내는 역할

### 3\. 기술적 고려 사항

#### 3.1. 웹 크롤러 알고리즘: DFS or BFS

웹은 어느 정도로 깊이 갈지 가늠하기 어렵기 때문에 보통 BFS를 사용

-   **BFS (너비 우선 탐색):** 얕고 넓게 크롤링 (일반적인 웹 크롤러).
-   **DFS (깊이 우선 탐색):** 특정 경로를 깊게 파고듦.

#### 3.2. 중복 제거(Deduping)

같은 페이지를 여러 번 방문하면 리소스 낭비 및 무한 루프 발생

-   **해시(Hash) 활용:** URL을 MD5나 SHA-256으로 해싱하여 저장 공간 절약.
-   **블룸 필터(Bloom Filter):** 메모리를 극도로 적게 쓰면서 "방문 여부"를 확률적으로 판단하는 자료구조.

#### 3.3. 예의 지키기(Politeness)

-   웹 크롤러는 수집 대상 서버로 짧은 시간에 너무 많은 요청을 보내는 것을 삼가 해야 함. 예의없는(impolite) 크롤링 금지
    -   따라서 DFS 보단 BFS 를 쓰는 듯
-   **Robots.txt 준수:** 웹사이트 소유자가 명시한 크롤링 규칙을 따름.
-   **Delay 설정:** 요청 간에 간격을 두어 대상 서버에 과부하를 주지 않음 (DoS 공격 오해 방지).

### 4\. 난관과 해결 방안 (Troubleshooting)

-   실무에서 마주하는 문제들

| **문제 상황** | **해결 방안** |
| --- | --- |
| **동적 페이지 (SPA)** | JavaScript로 렌더링되는 페이지(React, Vue 등)는 일반 HTTP 요청으로 데이터가 안 보임.   **Selenium, Puppeteer, Playwright** 같은 Headless Browser 사용. |
| **차단 (Anti-Scraping)** | IP 차단, 캡차(CAPTCHA) 등의 방어 기법.   **IP 회전(Proxy Pool)**, User-Agent 변경, 요청 헤더 조작으로 회피. |
| **무한 URL (Spider Trap)** | 캘린더 등 끝없이 생성되는 링크.   **최대 깊이(Max Depth)** 제한 설정. |
| **콘텐츠 변경 감지** | 이미 수집한 페이지가 업데이트되었는지 확인.   **Last-Modified 헤더** 확인 또는 콘텐츠 해시 비교. |

### 5\. 데이터 저장소

-   **관계형 DB (RDBMS - MySQL, PostgreSQL):** 데이터 구조가 정형화되어 있고 트랜잭션이 중요한 경우.
-   **NoSQL (MongoDB, Cassandra):** HTML 원본이나 비정형 데이터를 저장할 때 유리. 쓰기 속도가 빠르고 확장이 용이함.
-   **Elasticsearch:** 수집한 텍스트 데이터의 **검색** 기능이 필요할 때.

### 6\. 법적 및 윤리적 이슈

-   **저작권법:** 수집한 데이터를 상업적으로 이용하거나 무단 배포 시 법적 분쟁 가능성.
-   **서비스 이용 약관 (ToS):** 크롤링 금지 조항이 있는지 확인.
-   **개인정보:** PII(개인식별정보) 수집 주의.

### 7\. 기술 스택 종류

-   **Python:** Scrapy(프레임워크), BeautifulSoup(파싱), Selenium(동적), Celery(분산 처리).
-   **Java:** Jsoup(파싱), Spring Batch(배치 처리).
-   **Infra:** Kafka(메시지 큐), Redis(URL Frontier/캐시), AWS Lambda(서버리스 크롤러).